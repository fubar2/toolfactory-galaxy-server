<?xml version="1.0"?>
{% import "macros.xml.j2" as macros with context %}
<job_conf>
    <plugins workers="2">
{% if galaxy_extras_config_slurm %}
        <plugin id="slurm" type="runner" load="galaxy.jobs.runners.slurm:SlurmJobRunner">
            <param id="drmaa_library_path">/usr/lib/slurm-drmaa/lib/libdrmaa.so</param>
{% if galaxy_minimum_version >= "17.09" %}
            <param id="enabled" from_environ="GALAXY_RUNNERS_ENABLE_SLURM">true</param>
{% endif %}
        </plugin>
{% endif %}
{% if galaxy_extras_config_condor %}
        <plugin id="condor" type="runner" load="galaxy.jobs.runners.condor:CondorJobRunner">
{% if galaxy_minimum_version >= "17.09" %}
            <param id="enabled" from_environ="GALAXY_RUNNERS_ENABLE_CONDOR">true</param>
{% endif %}
        </plugin>
{% endif %}
{% if galaxy_extras_config_pbs %}
        <plugin id="pbs" type="runner" load="galaxy.jobs.runners.drmaa:DRMAAJobRunner">
            <param id="drmaa_library_path">/usr/lib/pbs-drmaa/lib/libdrmaa.so.1</param>
{% if galaxy_minimum_version >= "17.09" %}
            <param id="enabled" from_environ="GALAXY_RUNNERS_ENABLE_PBS">true</param>
{% endif %}
        </plugin>
{% endif %}
{% if galaxy_extras_config_k8s_jobs %}
        <plugin id="k8s" type="runner" load="galaxy.jobs.runners.kubernetes:KubernetesJobRunner">
            <!-- We are inside of Kubernetes so use this. -->
            <param id="k8s_use_service_account" from_environ="GALAXY_RUNNERS_K8S_USE_SERVICE_ACCOUNT">{{ galaxy_k8s_jobs_use_service_account }}</param>
            <param id="k8s_persistent_volume_claim_name" from_environ="GALAXY_RUNNERS_K8S_PERSISTENT_VOLUME_CLAIM_NAME">{{ galaxy_k8s_jobs_persistent_volume_claim_name }}</param>
            <param id="k8s_persistent_volume_claim_mount_path" from_environ="GALAXY_RUNNERS_K8S_PERSISTENT_VOLUME_CLAIM_MOUNT_PATH">{{ galaxy_k8s_jobs_persistent_volume_claim_mount_path }}</param>
            <param id="k8s_namespace" from_environ="GALAXY_RUNNERS_K8S_NAMESPACE">{{ galaxy_k8s_jobs_namespace }}</param>
            <param id="k8s_supplemental_group_id" from_environ="GALAXY_RUNNERS_K8S_SUPPLEMENTAL_GROUP_ID">{{ galaxy_k8s_jobs_supplemental_group_id }}</param>
            <param id="k8s_fs_group_id" from_environ="GALAXY_RUNNERS_K8S_FS_GROUP_ID">{{ galaxy_k8s_jobs_fs_group_id }}</param>
            <param id="k8s_pull_policy" from_environ="GALAXY_RUNNERS_K8S_PULL_POLICY">{{ galaxy_k8s_jobs_pull_policy }}</param>
            <param id="k8s_pod_retrials" from_environ="GALAXY_RUNNERS_K8S_POD_RETRIALS">{{ galaxy_k8s_jobs_pods_retrials }}</param>
{% if galaxy_minimum_version >= "17.09" %}
            <param id="enabled" from_environ="GALAXY_RUNNERS_ENABLE_K8">true</param>
{% endif %}
        </plugin>
{% endif %}
        <plugin id="local" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner"/>
    </plugins>
{% if not galaxy_mule_handlers %}
    <!-- The default handler can be changed by specifying the GALAXY_HANDLERS_DEFAULT environment variable. -->
    <handlers default_from_environ="GALAXY_HANDLERS_DEFAULT" default="handlers">
  {% if galaxy_handler_processes == 0 %}
        <handler id="web0" tags="handlers"/>
  {% else %}
    {% for i in range(galaxy_handler_processes) %}
        <handler id="handler{{ i }}" tags="handlers"/>
    {% endfor %}
  {% endif %}
    </handlers>
{% else %}
    <!-- uWSGI mule job handlers are enabled, so the <handlers> section is not used -->
{% endif %}
    <!-- The default destination can be changed by specifying the GALAXY_DESTINATIONS_DEFAULT environment variable. -->
    <destinations default_from_environ="GALAXY_DESTINATIONS_DEFAULT" default="{{ galaxy_extras_galaxy_destination_default }}">
        <destination id="docker_dispatch" runner="dynamic">
            <!-- Allow different default destinations based on whether the tool
                 supports Docker or not. -->
            <param id="type">docker_dispatch</param>
            <param id="docker_destination_id" from_environ="GALAXY_DESTINATIONS_DOCKER_DEFAULT">{{ galaxy_extras_galaxy_destination_docker_default }}</param>
            <param id="default_destination_id" from_environ="GALAXY_DESTINATIONS_NO_DOCKER_DEFAULT">{{ galaxy_extras_galaxy_destination_default }}</param>
        </destination>
        <!--destination id="singularity_dispatch" runner="dynamic">
            <param id="type">singularity_dispatch</param>
            <param id="singularity_destination_id" from_environ="GALAXY_DESTINATIONS_DOCKER_DEFAULT">{{ galaxy_extras_galaxy_destination_singularity_default }}</param>
            <param id="default_destination_id" from_environ="GALAXY_DESTINATIONS_NO_DOCKER_DEFAULT">{{ galaxy_extras_galaxy_destination_default }}</param>
        </destination-->
        {% call macros.destination("local_no_container", "local") %}{% endcall %}
        {% call macros.destination("local_docker", "local", container_type="docker") %}{% endcall %}
        {% call macros.destination("local_force_docker", "local", container_type="docker", force_container=True) %}{% endcall %}
{% if galaxy_extras_config_pbs %}
        {% call macros.destination("pbs_cluster", "pbs") %}{% endcall %}
        {% call macros.destination("pbs_cluster_docker", "pbs", container_type="docker") %}{% endcall %}
        {% call macros.destination("pbs_cluster_force_docker", "pbs", container_type="docker", force_container=True) %}{% endcall %}
{% endif %}
{% if galaxy_extras_config_slurm %}
        {% call macros.destination("slurm_cluster", "slurm") %}
            <param id="nativeSpecification" from_environ="NATIVE_SPEC">--ntasks={{ galaxy_extras_slurm_ntask }} --share</param>
        {% endcall %}
        <!-- Docker -->
        {% call macros.destination("slurm_cluster_docker", "slurm", container_type="docker") %}
            <param id="nativeSpecification" from_environ="NATIVE_SPEC">--ntasks={{ galaxy_extras_slurm_ntask }} --share</param>
        {% endcall %}
        {% call macros.destination("slurm_cluster_force_docker", "slurm", container_type="docker", force_container=True) %}
            <param id="nativeSpecification" from_environ="NATIVE_SPEC">--ntasks={{ galaxy_extras_slurm_ntask }} --share</param>
        {% endcall %}
        <!-- Singularity -->
        {% call macros.destination("slurm_cluster_singularity", "slurm", container_type="singularity") %}
            <param id="nativeSpecification" from_environ="NATIVE_SPEC">--ntasks={{ galaxy_extras_slurm_ntask }} --share</param>
        {% endcall %}

{% endif %}
{% if galaxy_extras_config_condor %}
        {% call macros.destination("condor_cluster", "condor") %}
            <param id="universe" from_environ="GALAXY_CONDOR_UNIVERSE">vanilla</param>
        {% endcall %}
        {% call macros.destination("condor_cluster_docker", "condor", container_type="docker") %}
            <param id="universe" from_environ="GALAXY_CONDOR_UNIVERSE">vanilla</param>
        {% endcall %}
        {% call macros.destination("condor_cluster_force_docker", "condor", container_type="docker", force_container=True) %}
            <param id="universe" from_environ="GALAXY_CONDOR_UNIVERSE">vanilla</param>
        {% endcall %}
        {% call macros.destination("condor_docker_universe", "condor", container_type="docker", force_container=True) %}
            <param id="universe" from_environ="GALAXY_CONDOR_UNIVERSE">docker</param>
        {% endcall %}
        <!-- Following destinations send to basic Condor runner if no Docker image is available
             otherwise they both use the Docker image - the first submits a normal Condor job
             that will run Docker on the resulting worker node and the second uses Condor's
             native Docker universe support.
        -->
        {{ macros.docker_dispatch_destination("condor_docker_cluster_dispatch", "condor_cluster_docker", "condor_cluster")}}
        {{ macros.docker_dispatch_destination("condor_docker_universe_dispatch", "condor_docker_universe", "condor_cluster")}}
{% endif %}
{% if galaxy_extras_config_k8s_jobs %}
        {% call macros.destination("k8s_default", "k8s", container_type="docker", force_container=True) %}{% endcall %}
        {{ macros.docker_dispatch_destination("k8s_or_local_dispatch", "k8s_default", "local_no_container")}}
        {{ macros.docker_dispatch_destination("k8s_or_slurm_dispatch", "k8s_default", "slurm_cluster")}}
        {{ macros.docker_dispatch_destination("k8s_or_condor_dispatch", "k8s_default", "condor_cluster")}}
{% endif %}
    </destinations>
    <limits>
    </limits>
</job_conf>
